{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebe1155a-9e14-4c47-bccb-fdb1f2604def",
   "metadata": {},
   "source": [
    "# Lab 3. Text-completion with GenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2ea3b7-4e7b-4782-b35d-50fb4576ad8d",
   "metadata": {},
   "source": [
    "### Download Qwen2-7B-Instruct model from ModelScope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7d35c93-6341-4422-a41f-ea084d597579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from modelscope import snapshot_download\n",
    "llm_model_id = \"snake7gun/Qwen2-7B-Instruct-int4-ov\"\n",
    "llm_local_path  = \"./model/snake7gun/Qwen2-7B-Instruct-int4-ov\"\n",
    "\n",
    "if not Path(llm_local_path).exists():\n",
    "    model_dir = snapshot_download(llm_model_id, cache_dir=\"./model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49e8764-25a6-4d42-8a8e-30e0db792199",
   "metadata": {},
   "source": [
    "### Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83ebf4f1-a5b3-4c9a-a98f-bc885ebf6549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino_genai\n",
    "\n",
    "pipe = openvino_genai.LLMPipeline(llm_local_path, \"GPU\")\n",
    "\n",
    "def streamer(subword):\n",
    "    print(subword, end='', flush=True)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f06970-6bc2-4e50-85fe-cc49c35c31dd",
   "metadata": {},
   "source": [
    "### Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ef4d999-04c7-4b1a-ad42-1b2e6cdc4bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenVINO（Open Visual Inference and Neural Network Optimization）是由英特尔开发的一套开源工具套件，用于在各种设备上部署深度学习模型。它提供了一系列的API和工具，使得开发者能够将训练好的神经网络模型部署到不同的硬件平台上，包括CPU、GPU、FPGA等。\n",
      "\n",
      "OpenVINO的主要功能包括：\n",
      "\n",
      "1. **模型优化**：它能够优化神经网络模型，以适应不同的硬件平台，提高模型的运行效率。\n",
      "\n",
      "2. **模型推理**：提供API用于在各种硬件平台上执行模型的推理任务，即使用模型进行预测或分类。\n",
      "\n",
      "3. **支持多种模型格式**：支持多种深度学习模型格式，如ONNX、TensorFlow、Caffe等。\n",
      "\n",
      "4. **硬件加速**：通过利用硬件加速技术，如Intel的GPU"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|im_start|>system\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m<|im_end|>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m<|im_start|>user\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m什么是OpenVINO？<|im_end|>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m<|im_start|>assistant\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m151645\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m, in \u001b[0;36mstreamer\u001b[1;34m(subword)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstreamer\u001b[39m(subword):\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflush\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prompt = \"<|im_start|>system\\n<|im_end|>\\n<|im_start|>user\\n什么是OpenVINO？<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "pipe.generate(prompt, eos_token_id=151645, max_length=500, streamer=streamer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa565b0c-79df-4cc4-9ad9-d9b86c49dac9",
   "metadata": {},
   "source": [
    "### Chat Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fcf60c-cba4-4225-89e5-83958c605aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.start_chat()\n",
    "config = openvino_genai.GenerationConfig()\n",
    "config.max_new_tokens = 200\n",
    "config.do_sample = True\n",
    "config.top_p = 0.9\n",
    "config.top_k = 30\n",
    "pipe.generate(\"请讲一个有趣的故事\", config, streamer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176a0530-7ea2-4e28-b6a3-86099163dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.generate(\"给这个故事起一个标题\", config, streamer)\n",
    "pipe.finish_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfafe9c0",
   "metadata": {},
   "source": [
    "### MiniCPM-2B-dpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b5f7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from modelscope import snapshot_download\n",
    "\n",
    "llm_model_id = \"snake7gun/minicpm-2b-dpo-int4-ov\"\n",
    "llm_local_path  = \"./model/\" + llm_model_id\n",
    "\n",
    "if not Path(llm_local_path).exists():\n",
    "    model_dir = snapshot_download(llm_model_id, cache_dir=\"./model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a8374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = openvino_genai.LLMPipeline(llm_local_path, \"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ec038",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"<用户>什么是人工智能？<AI>\"\n",
    "pipe.generate(prompt, eos_token_id=2, max_length=500, streamer=streamer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
